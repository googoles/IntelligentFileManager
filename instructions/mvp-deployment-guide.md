# MVP ì‹¤í–‰, ë°°í¬ ë° í™•ì¥ ê°€ì´ë“œ

## ğŸ¯ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ One-Click ì„¤ì •

### ìë™ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ (setup.py)
```python
#!/usr/bin/env python3
"""
Research File Manager MVP - ì›í´ë¦­ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
ì‹¤í–‰: python setup.py
"""

import os
import sys
import subprocess
import platform
from pathlib import Path

class MVPSetup:
    def __init__(self):
        self.root_dir = Path.cwd()
        self.venv_dir = self.root_dir / "venv"
        self.is_windows = platform.system() == "Windows"
        
    def print_banner(self):
        """ì„¤ì¹˜ ë°°ë„ˆ ì¶œë ¥"""
        print("""
        â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
        â•‘   Research File Manager MVP - Auto Setup    â•‘
        â•‘           ğŸš€ ì›í´ë¦­ ìë™ ì„¤ì¹˜ ğŸš€            â•‘
        â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)
        
    def check_python(self):
        """Python ë²„ì „ í™•ì¸"""
        print("ğŸ“Œ Python ë²„ì „ í™•ì¸...")
        version = sys.version_info
        if version.major < 3 or (version.major == 3 and version.minor < 8):
            print("âŒ Python 3.8 ì´ìƒì´ í•„ìš”í•©ë‹ˆë‹¤!")
            sys.exit(1)
        print(f"âœ… Python {version.major}.{version.minor}.{version.micro}")
        
    def create_venv(self):
        """ê°€ìƒí™˜ê²½ ìƒì„±"""
        print("\nğŸ“Œ ê°€ìƒí™˜ê²½ ìƒì„±...")
        if self.venv_dir.exists():
            print("âš ï¸  ê¸°ì¡´ ê°€ìƒí™˜ê²½ ë°œê²¬, ê±´ë„ˆëœ€")
            return
            
        subprocess.run([sys.executable, "-m", "venv", "venv"])
        print("âœ… ê°€ìƒí™˜ê²½ ìƒì„± ì™„ë£Œ")
        
    def get_pip_cmd(self):
        """OSë³„ pip ê²½ë¡œ ë°˜í™˜"""
        if self.is_windows:
            return str(self.venv_dir / "Scripts" / "pip.exe")
        return str(self.venv_dir / "bin" / "pip")
        
    def install_requirements(self):
        """íŒ¨í‚¤ì§€ ì„¤ì¹˜"""
        print("\nğŸ“Œ í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜...")
        pip_cmd = self.get_pip_cmd()
        
        requirements = [
            "fastapi==0.104.1",
            "uvicorn[standard]==0.24.0",
            "watchdog==3.0.0",
            "sentence-transformers==2.2.2",
            "chromadb==0.4.18",
            "sqlalchemy==2.0.23",
            "aiofiles==23.2.1",
            "python-multipart==0.0.6",
            "pydantic==2.5.0",
            "python-dotenv==1.0.0"
        ]
        
        # í•œ ë²ˆì— ì„¤ì¹˜ (ë” ë¹ ë¦„)
        subprocess.run([pip_cmd, "install"] + requirements)
        print("âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ")
        
    def create_directory_structure(self):
        """ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±"""
        print("\nğŸ“Œ í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±...")
        
        directories = [
            "backend",
            "frontend", 
            "data/projects",
            "data/db",
            "data/db/chroma",
            "logs",
            "tests"
        ]
        
        for dir_path in directories:
            Path(dir_path).mkdir(parents=True, exist_ok=True)
            
        print("âœ… ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì™„ë£Œ")
        
    def create_env_file(self):
        """í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ ìƒì„±"""
        print("\nğŸ“Œ í™˜ê²½ ì„¤ì • íŒŒì¼ ìƒì„±...")
        
        env_content = """# Research File Manager MVP Configuration
ENV=development
HOST=0.0.0.0
PORT=8000

# Database
DATABASE_URL=sqlite:///data/db/research.db

# Model Settings  
EMBEDDING_MODEL=all-MiniLM-L6-v2
MAX_CHUNK_SIZE=500

# File Processing
SUPPORTED_EXTENSIONS=.txt,.md,.py,.js,.json,.csv,.pdf
MAX_FILE_SIZE_MB=100

# Optional API Keys (í´ë¼ìš°ë“œ ê¸°ëŠ¥ìš©)
# OPENAI_API_KEY=your_key_here
# ANTHROPIC_API_KEY=your_key_here
"""
        
        with open(".env", "w") as f:
            f.write(env_content)
            
        print("âœ… .env íŒŒì¼ ìƒì„± ì™„ë£Œ")
        
    def download_core_files(self):
        """í•µì‹¬ íŒŒì¼ ë‹¤ìš´ë¡œë“œ/ìƒì„±"""
        print("\nğŸ“Œ í•µì‹¬ íŒŒì¼ ìƒì„±...")
        
        # ì—¬ê¸°ì„œëŠ” íŒŒì¼ì„ ì§ì ‘ ìƒì„±
        # ì‹¤ì œë¡œëŠ” GitHubì—ì„œ ë‹¤ìš´ë¡œë“œí•˜ê±°ë‚˜ í…œí”Œë¦¿ ì‚¬ìš©
        
        # requirements.txt ìƒì„±
        with open("requirements.txt", "w") as f:
            f.write("""fastapi==0.104.1
uvicorn[standard]==0.24.0
watchdog==3.0.0
sentence-transformers==2.2.2
chromadb==0.4.18
sqlalchemy==2.0.23
aiofiles==23.2.1
python-multipart==0.0.6
pydantic==2.5.0
python-dotenv==1.0.0
pypdf2==3.0.1
python-docx==1.1.0
easyocr==1.7.1
ollama==0.1.7""")
        
        print("âœ… requirements.txt ìƒì„± ì™„ë£Œ")
        
    def create_run_scripts(self):
        """ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
        print("\nğŸ“Œ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±...")
        
        # Windows ë°°ì¹˜ íŒŒì¼
        with open("run.bat", "w") as f:
            f.write("""@echo off
echo Starting Research File Manager MVP...
call venv\\Scripts\\activate
python backend\\main.py
pause""")
            
        # Unix ì‰˜ ìŠ¤í¬ë¦½íŠ¸  
        with open("run.sh", "w") as f:
            f.write("""#!/bin/bash
echo "Starting Research File Manager MVP..."
source venv/bin/activate
python backend/main.py""")
            
        if not self.is_windows:
            os.chmod("run.sh", 0o755)
            
        print("âœ… ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ")
        
    def download_models(self):
        """ML ëª¨ë¸ ì‚¬ì „ ë‹¤ìš´ë¡œë“œ"""
        print("\nğŸ“Œ ML ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì²« ì‹¤í–‰ ì†ë„ í–¥ìƒ)...")
        
        try:
            from sentence_transformers import SentenceTransformer
            print("   ë‹¤ìš´ë¡œë“œ ì¤‘... (ì•½ 90MB)")
            model = SentenceTransformer('all-MiniLM-L6-v2')
            print("âœ… ì„ë² ë”© ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ì²« ì‹¤í–‰ì‹œ ìë™ ë‹¤ìš´ë¡œë“œ): {e}")
            
    def create_sample_data(self):
        """ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
        print("\nğŸ“Œ ìƒ˜í”Œ í”„ë¡œì íŠ¸ ìƒì„±...")
        
        sample_dir = Path("data/projects/sample_project")
        sample_dir.mkdir(parents=True, exist_ok=True)
        
        # ìƒ˜í”Œ íŒŒì¼ë“¤
        samples = {
            "README.md": "# Sample Research Project\n\nThis is a sample project for testing.",
            "data_analysis.py": "import pandas as pd\n# Sample analysis code\ndf = pd.read_csv('data.csv')",
            "notes.txt": "Research notes:\n- Experiment 1: Success\n- TODO: Review literature",
            "results.json": '{"accuracy": 0.95, "loss": 0.05}'
        }
        
        for filename, content in samples.items():
            (sample_dir / filename).write_text(content)
            
        print("âœ… ìƒ˜í”Œ í”„ë¡œì íŠ¸ ìƒì„± ì™„ë£Œ")
        
    def print_next_steps(self):
        """ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´"""
        run_cmd = "run.bat" if self.is_windows else "./run.sh"
        
        print(f"""
        â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
        â•‘            âœ¨ ì„¤ì¹˜ ì™„ë£Œ! âœ¨                 â•‘
        â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        ğŸ¯ ì‹¤í–‰ ë°©ë²•:
        {run_cmd}
        
        ë˜ëŠ”:
        
        {'venv\\Scripts\\activate' if self.is_windows else 'source venv/bin/activate'}
        python backend/main.py
        
        ğŸ“± ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†:
        http://localhost:8000
        
        ğŸ“š ìƒ˜í”Œ í”„ë¡œì íŠ¸:
        data/projects/sample_project/
        
        ğŸ’¡ ë„ì›€ë§:
        - Ctrl+Cë¡œ ì„œë²„ ì¤‘ì§€
        - logs/ í´ë”ì—ì„œ ë¡œê·¸ í™•ì¸
        - .env íŒŒì¼ì—ì„œ ì„¤ì • ë³€ê²½
        """)
        
    def run(self):
        """ì „ì²´ ì„¤ì¹˜ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        try:
            self.print_banner()
            self.check_python()
            self.create_venv()
            self.install_requirements()
            self.create_directory_structure()
            self.create_env_file()
            self.download_core_files()
            self.create_run_scripts()
            self.download_models()
            self.create_sample_data()
            self.print_next_steps()
            
            print("\nğŸ‰ ì„¤ì¹˜ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
        except Exception as e:
            print(f"\nâŒ ì„¤ì¹˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print("ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ìˆ˜ë™ ì„¤ì¹˜ë¥¼ ì‹œë„í•˜ì„¸ìš”.")
            sys.exit(1)

if __name__ == "__main__":
    setup = MVPSetup()
    setup.run()
```

## ğŸ³ Dockerë¥¼ í†µí•œ ì›í´ë¦­ ë°°í¬

### Dockerfile
```dockerfile
FROM python:3.10-slim

WORKDIR /app

# ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    git \
    && rm -rf /var/lib/apt/lists/*

# íŒŒì´ì¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì• í”Œë¦¬ì¼€ì´ì…˜ íŒŒì¼ ë³µì‚¬
COPY backend/ ./backend/
COPY frontend/ ./frontend/

# ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
RUN mkdir -p data/projects data/db logs

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8000

# ì‹¤í–‰
CMD ["uvicorn", "backend.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### docker-compose.yml
```yaml
version: '3.8'

services:
  research-manager:
    build: .
    container_name: research-file-manager
    ports:
      - "8000:8000"
    volumes:
      # ë°ì´í„° ì˜ì†ì„±
      - ./data:/app/data
      - ./logs:/app/logs
      # í˜¸ìŠ¤íŠ¸ íŒŒì¼ ì‹œìŠ¤í…œ ë§ˆìš´íŠ¸ (ì„ íƒì )
      - ~/Documents/Research:/app/external/research
    environment:
      - ENV=production
      - DATABASE_URL=sqlite:///app/data/db/research.db
      - EMBEDDING_MODEL=all-MiniLM-L6-v2
    restart: unless-stopped
    networks:
      - research-net

  # ì„ íƒì : PostgreSQL (í™•ì¥ì„±ì„ ìœ„í•´)
  postgres:
    image: postgres:15-alpine
    container_name: research-db
    environment:
      POSTGRES_USER: research
      POSTGRES_PASSWORD: secure_password
      POSTGRES_DB: research_files
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - research-net
    profiles:
      - full

networks:
  research-net:
    driver: bridge

volumes:
  postgres_data:
```

## ğŸ”§ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ í™•ì¥ ê¸°ëŠ¥

### 1. PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ (5ë¶„ ì¶”ê°€)
```python
# backend/pdf_processor.py
import PyPDF2
from typing import Optional

class PDFProcessor:
    @staticmethod
    def extract_text(file_path: str) -> Optional[str]:
        """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            with open(file_path, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                text = ""
                
                for page_num in range(len(reader.pages)):
                    page = reader.pages[page_num]
                    text += page.extract_text() + "\n"
                
                return text.strip()
        except Exception as e:
            print(f"PDF ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    @staticmethod
    def extract_metadata(file_path: str) -> dict:
        """PDF ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        try:
            with open(file_path, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                info = reader.metadata
                
                return {
                    'title': info.get('/Title', ''),
                    'author': info.get('/Author', ''),
                    'subject': info.get('/Subject', ''),
                    'pages': len(reader.pages)
                }
        except:
            return {}
```

### 2. ì‹¤ì‹œê°„ í˜‘ì—… (WebSocket) - 10ë¶„ ì¶”ê°€
```python
# backend/websocket_manager.py
from fastapi import WebSocket
from typing import List, Dict
import json

class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, List[WebSocket]] = {}
    
    async def connect(self, websocket: WebSocket, project_id: str):
        await websocket.accept()
        if project_id not in self.active_connections:
            self.active_connections[project_id] = []
        self.active_connections[project_id].append(websocket)
        
    def disconnect(self, websocket: WebSocket, project_id: str):
        self.active_connections[project_id].remove(websocket)
        
    async def broadcast_file_change(self, project_id: str, message: dict):
        """í”„ë¡œì íŠ¸ ë‚´ ëª¨ë“  ì‚¬ìš©ìì—ê²Œ íŒŒì¼ ë³€ê²½ ì•Œë¦¼"""
        if project_id in self.active_connections:
            for connection in self.active_connections[project_id]:
                await connection.send_json(message)

# main.pyì— ì¶”ê°€
manager = ConnectionManager()

@app.websocket("/ws/{project_id}")
async def websocket_endpoint(websocket: WebSocket, project_id: str):
    await manager.connect(websocket, project_id)
    try:
        while True:
            data = await websocket.receive_text()
            # ë©”ì‹œì§€ ì²˜ë¦¬
    except:
        manager.disconnect(websocket, project_id)
```

### 3. Ollama ë¡œì»¬ LLM í†µí•© (15ë¶„ ì¶”ê°€)
```python
# backend/llm_service.py
import ollama
from typing import Optional, List
import asyncio

class LocalLLMService:
    def __init__(self, model_name: str = "llama3.2:3b"):
        self.model = model_name
        self.client = ollama.Client()
        
    async def summarize_document(self, content: str) -> str:
        """ë¬¸ì„œ ìš”ì•½"""
        prompt = f"""Summarize the following document in 3-5 bullet points:

{content[:2000]}

Summary:"""
        
        response = await asyncio.to_thread(
            self.client.chat,
            model=self.model,
            messages=[{"role": "user", "content": prompt}]
        )
        
        return response['message']['content']
    
    async def extract_keywords(self, content: str) -> List[str]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        prompt = f"""Extract 5-10 key technical terms from this text:

{content[:1000]}

Keywords (comma-separated):"""
        
        response = await asyncio.to_thread(
            self.client.chat,
            model=self.model,
            messages=[{"role": "user", "content": prompt}]
        )
        
        keywords = response['message']['content'].split(',')
        return [k.strip() for k in keywords]
    
    async def suggest_file_category(self, content: str, filename: str) -> str:
        """íŒŒì¼ ì¹´í…Œê³ ë¦¬ ì œì•ˆ"""
        prompt = f"""Given this filename and content, suggest the best category:
Filename: {filename}
Content preview: {content[:500]}

Categories: literature, data, code, results, notes, other

Best category:"""
        
        response = await asyncio.to_thread(
            self.client.chat,
            model=self.model,
            messages=[{"role": "user", "content": prompt}]
        )
        
        return response['message']['content'].strip().lower()
```

## ğŸ“± ë°ìŠ¤í¬í†± ì•± íŒ¨í‚¤ì§• (Electron)

### electron-app/package.json
```json
{
  "name": "research-file-manager",
  "version": "1.0.0",
  "description": "AI-Powered Research File Manager",
  "main": "main.js",
  "scripts": {
    "start": "electron .",
    "build-win": "electron-builder --win",
    "build-mac": "electron-builder --mac",
    "build-linux": "electron-builder --linux"
  },
  "devDependencies": {
    "electron": "^27.0.0",
    "electron-builder": "^24.0.0"
  },
  "build": {
    "appId": "com.research.filemanager",
    "productName": "Research File Manager",
    "directories": {
      "output": "dist"
    },
    "files": [
      "main.js",
      "preload.js",
      "renderer/**/*",
      "backend/**/*",
      "!backend/__pycache__"
    ],
    "win": {
      "target": "nsis",
      "icon": "assets/icon.ico"
    },
    "mac": {
      "target": "dmg",
      "icon": "assets/icon.icns"
    },
    "linux": {
      "target": "AppImage",
      "icon": "assets/icon.png"
    }
  }
}
```

### electron-app/main.js
```javascript
const { app, BrowserWindow, Menu, Tray, shell } = require('electron');
const path = require('path');
const { spawn } = require('child_process');

let mainWindow;
let pythonProcess;
let tray;

// Python ë°±ì—”ë“œ ì‹œì‘
function startPythonBackend() {
  const script = path.join(__dirname, '../backend/main.py');
  const python = process.platform === 'win32' ? 'python' : 'python3';
  
  pythonProcess = spawn(python, [script]);
  
  pythonProcess.stdout.on('data', (data) => {
    console.log(`Python: ${data}`);
  });
  
  pythonProcess.stderr.on('data', (data) => {
    console.error(`Python Error: ${data}`);
  });
}

// ë©”ì¸ ìœˆë„ìš° ìƒì„±
function createWindow() {
  mainWindow = new BrowserWindow({
    width: 1400,
    height: 900,
    icon: path.join(__dirname, 'assets/icon.png'),
    webPreferences: {
      nodeIntegration: false,
      contextIsolation: true,
      preload: path.join(__dirname, 'preload.js')
    },
    titleBarStyle: 'hiddenInset',
    backgroundColor: '#1e1e1e'
  });

  // ë°±ì—”ë“œê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°
  setTimeout(() => {
    mainWindow.loadURL('http://localhost:8000');
  }, 3000);

  // ê°œë°œì ë„êµ¬ (ê°œë°œ ëª¨ë“œì—ì„œë§Œ)
  if (process.env.NODE_ENV === 'development') {
    mainWindow.webContents.openDevTools();
  }
}

// ì‹œìŠ¤í…œ íŠ¸ë ˆì´
function createTray() {
  tray = new Tray(path.join(__dirname, 'assets/tray-icon.png'));
  
  const contextMenu = Menu.buildFromTemplate([
    { label: 'ì—´ê¸°', click: () => mainWindow.show() },
    { label: 'ì„¤ì •', click: () => shell.openPath(path.join(__dirname, '../.env')) },
    { type: 'separator' },
    { label: 'ì¢…ë£Œ', click: () => app.quit() }
  ]);
  
  tray.setToolTip('Research File Manager');
  tray.setContextMenu(contextMenu);
  
  tray.on('click', () => {
    mainWindow.isVisible() ? mainWindow.hide() : mainWindow.show();
  });
}

// ì•± ì‹œì‘
app.whenReady().then(() => {
  startPythonBackend();
  createWindow();
  createTray();
});

// ì•± ì¢…ë£Œ ì²˜ë¦¬
app.on('before-quit', () => {
  if (pythonProcess) {
    pythonProcess.kill();
  }
});

app.on('window-all-closed', () => {
  if (process.platform !== 'darwin') {
    app.quit();
  }
});
```

## ğŸƒâ€â™‚ï¸ ë¹ ë¥¸ ì‹œì‘ ëª…ë ¹ì–´ ëª¨ìŒ

### 1. Git Clone & ìë™ ì„¤ì¹˜ (1ë¶„)
```bash
# GitHubì—ì„œ í´ë¡  (ì‹¤ì œ ë ˆí¬ì§€í† ë¦¬ URLë¡œ ë³€ê²½)
git clone https://github.com/yourusername/research-file-manager.git
cd research-file-manager

# ìë™ ì„¤ì¹˜
python setup.py

# ì‹¤í–‰
./run.sh  # Mac/Linux
run.bat   # Windows
```

### 2. Docker ì‹¤í–‰ (2ë¶„)
```bash
# ë¹Œë“œ ë° ì‹¤í–‰
docker-compose up -d

# ë¡œê·¸ í™•ì¸
docker-compose logs -f

# ì¤‘ì§€
docker-compose down
```

### 3. ê°œë°œ ëª¨ë“œ ì‹¤í–‰
```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™”
source venv/bin/activate  # Mac/Linux
venv\Scripts\activate     # Windows

# ê°œë°œ ì„œë²„ ì‹¤í–‰ (ìë™ ë¦¬ë¡œë“œ)
uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000

# ë³„ë„ í„°ë¯¸ë„ì—ì„œ í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œ ì„œë²„
cd frontend
python -m http.server 3000
```

## ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

### backend/monitoring.py
```python
from datetime import datetime, timedelta
from typing import Dict, List
import psutil
import asyncio
from collections import deque

class PerformanceMonitor:
    def __init__(self, max_history: int = 100):
        self.metrics_history = deque(maxlen=max_history)
        self.start_time = datetime.now()
        
    async def collect_metrics(self) -> Dict:
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        metrics = {
            'timestamp': datetime.now().isoformat(),
            'cpu_percent': psutil.cpu_percent(interval=1),
            'memory': {
                'used': psutil.virtual_memory().used / (1024**3),  # GB
                'percent': psutil.virtual_memory().percent
            },
            'disk': {
                'used': psutil.disk_usage('/').used / (1024**3),  # GB
                'percent': psutil.disk_usage('/').percent
            },
            'files_indexed': await self.get_indexed_files_count(),
            'active_searches': await self.get_active_searches(),
            'uptime': str(datetime.now() - self.start_time)
        }
        
        self.metrics_history.append(metrics)
        return metrics
    
    async def get_indexed_files_count(self) -> int:
        """ì¸ë±ì‹±ëœ íŒŒì¼ ìˆ˜"""
        # DB ì¿¼ë¦¬ë¡œ ì‹¤ì œ êµ¬í˜„
        return 1234  # ì˜ˆì‹œ
    
    async def get_active_searches(self) -> int:
        """í™œì„± ê²€ìƒ‰ ìˆ˜"""
        return 5  # ì˜ˆì‹œ
    
    def get_dashboard_data(self) -> Dict:
        """ëŒ€ì‹œë³´ë“œìš© ë°ì´í„°"""
        return {
            'current': self.metrics_history[-1] if self.metrics_history else {},
            'history': list(self.metrics_history),
            'summary': {
                'avg_cpu': sum(m['cpu_percent'] for m in self.metrics_history) / len(self.metrics_history) if self.metrics_history else 0,
                'peak_memory': max((m['memory']['percent'] for m in self.metrics_history), default=0)
            }
        }

# API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
monitor = PerformanceMonitor()

@app.get("/api/metrics")
async def get_metrics():
    """ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­"""
    return await monitor.collect_metrics()

@app.get("/api/dashboard")
async def get_dashboard():
    """ëŒ€ì‹œë³´ë“œ ë°ì´í„°"""
    return monitor.get_dashboard_data()
```

## ğŸ¯ í”„ë¡œë•ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë³´ì•ˆ
- [ ] API ì¸ì¦ ì¶”ê°€ (JWT)
- [ ] HTTPS ì„¤ì • (Let's Encrypt)
- [ ] íŒŒì¼ ì—…ë¡œë“œ ê²€ì¦
- [ ] SQL Injection ë°©ì§€
- [ ] Rate Limiting

### ì„±ëŠ¥
- [ ] ì¸ë±ìŠ¤ ìµœì í™”
- [ ] ìºì‹± ë ˆì´ì–´ (Redis)
- [ ] ë¹„ë™ê¸° ì‘ì—… í (Celery)
- [ ] CDN ì •ì  íŒŒì¼

### ëª¨ë‹ˆí„°ë§
- [ ] ë¡œê¹… ì‹œìŠ¤í…œ (ELK Stack)
- [ ] ì—ëŸ¬ ì¶”ì  (Sentry)
- [ ] ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ (Prometheus)
- [ ] ì•Œë¦¼ ì‹œìŠ¤í…œ

### ë°±ì—…
- [ ] ìë™ ë°±ì—… ìŠ¤í¬ë¦½íŠ¸
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ë³µì œ
- [ ] íŒŒì¼ ì‹œìŠ¤í…œ ìŠ¤ëƒ…ìƒ·
- [ ] ì¬í•´ ë³µêµ¬ ê³„íš

## ğŸ’¡ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œì™€ í•´ê²°

**1. í¬íŠ¸ ì´ë¯¸ ì‚¬ìš© ì¤‘**
```bash
# í¬íŠ¸ í™•ì¸
lsof -i :8000  # Mac/Linux
netstat -ano | findstr :8000  # Windows

# í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ë˜ëŠ” í¬íŠ¸ ë³€ê²½
uvicorn backend.main:app --port 8001
```

**2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨**
```python
# ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('all-MiniLM-L6-v2', cache_folder='./models')
```

**3. ë©”ëª¨ë¦¬ ë¶€ì¡±**
```python
# ì²­í¬ í¬ê¸° ì¡°ì •
CHUNK_SIZE = 200  # 500ì—ì„œ ê°ì†Œ
BATCH_SIZE = 10   # ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸° ê°ì†Œ
```

**4. íŒŒì¼ ê¶Œí•œ ì˜¤ë¥˜**
```bash
# Unix/Linux
chmod -R 755 data/
sudo chown -R $USER:$USER data/

# Windows (ê´€ë¦¬ì ê¶Œí•œìœ¼ë¡œ ì‹¤í–‰)
```

ì´ì œ MVPê°€ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰ 

í•˜ë£¨ ì•ˆì— ì œì‘ ê°€ëŠ¥í•œ í•µì‹¬ ê¸°ëŠ¥ê³¼ í•¨ê»˜, ì¦‰ì‹œ í™•ì¥ ê°€ëŠ¥í•œ êµ¬ì¡°ë¥¼ ê°–ì¶”ì—ˆìŠµë‹ˆë‹¤. Claude Codeì™€ í•¨ê»˜ë¼ë©´ ê° ë¶€ë¶„ì„ ë¹ ë¥´ê²Œ êµ¬í˜„í•˜ê³  ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.